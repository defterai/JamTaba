#ifndef MAIN_CONTROLLER_H
#define MAIN_CONTROLLER_H

#include <QScopedPointer>
#include <QImage>
#include <QMutex>

#include "UploadIntervalData.h"
#include "loginserver/LoginService.h"
#include "persistence/Settings.h"
#include "persistence/UsersDataCache.h"
#include "midi/MidiDriver.h"
#include "video/FFMpegMuxer.h"
#include "gui/chat/EmojiManager.h"

class MainWindow;

namespace ninjam { namespace client {
class Service;
class ServerInfo;
class User;
struct ChannelMetadata;
}}

namespace persistence {
class LocalInputTrackSettings;
class Preset;
}

namespace audio {
class AudioNode;
class LocalInputNode;
class LocalInputGroup;
class AudioPeak;
class SamplesBuffer;
class AbstractMp3Streamer;
}

namespace recorder {
class JamRecorder;
}

namespace controller {

struct AudioChannelData;
class AudioController;
class NinjamController;

using ninjam::client::Service;
using ninjam::client::ServerInfo;
using ninjam::client::User;
using ninjam::client::ChannelMetadata;
using persistence::Settings;
using persistence::LocalInputTrackSettings;
using persistence::Preset;
using persistence::UsersDataCache;
using audio::AudioNode;
using audio::AudioPeak;
using audio::LocalInputNode;
using audio::LocalInputGroup;
using audio::SamplesBuffer;
using audio::AbstractMp3Streamer;
using login::RoomInfo;
using login::LoginService;
using recorder::JamRecorder;

class MainController : public QObject
{
    Q_OBJECT

    friend class controller::NinjamController;

protected:
    explicit MainController(const Settings &settings);

public:

    virtual ~MainController();

    virtual void start();
    virtual void stop();

    long getTotalUploadTransferRate() const;
    long getTotalDownloadTransferRate() const;
    long getDownloadTransferRate(const QString userFullName, quint8 channelIndex) const;

    void setVideoProperties(const QSize &resolution);

    QSize getVideoResolution() const;

    void setFullScreenView(bool fullScreen);

    virtual QString getJamtabaFlavor() const = 0;     // return Standalone or VstPlugin

    virtual void setMainWindow(MainWindow *mainWindow);

    MainWindow *getMainWindow() const;

    virtual QVector<midi::MidiMessage> pullMidiMessagesFromPlugins() = 0;     // pull midi messages generated by plugins. This function can be called many times in each audio processing cicle because every VSTi can be a midi messages generator, and we need get the generated messages after call the plugin 'process' function.

    LocalInputTrackSettings getLastInputsSettings() const;

    void saveLastUserSettings();

    // presets
    virtual Preset loadPreset(const QString &name);     // one preset
    QStringList getPresetList();     // return all presets names
    void savePreset(const LocalInputTrackSettings &inputsSettings,
                    const QString &name);
    void deletePreset(const QString &name);     // not used yet

    // main audio processing routine
    virtual void process(const QSharedPointer<audio::SamplesBuffer>& in, const QSharedPointer<audio::SamplesBuffer>& out);

    void sendNewChannelsNames(const QList<ChannelMetadata> &channels);
    void sendRemovedChannelMessage(int removedChannelIndex);

    inline QString getTheme() const
    {
        return settings.getTheme();
    }

    void playRoomStream(const RoomInfo &roomInfo);
    bool isPlayingRoomStream() const;

    bool isPlayingInNinjamRoom() const;
    virtual void stopNinjamController();

    void stopRoomStream();     // stop currentRoom stream
    QString getCurrentStreamingRoomID() const;

    int getLastTracksLayout() const;

    void storeTracksLayoutOrientation(quint8 layout);

    void storeTracksSize(bool usingNarrowedTracks);

    bool isUsingNarrowedTracks() const;

    void storeWaveDrawingMode(persistence::WaveDrawingMode drawingMode);

    persistence::WaveDrawingMode getLastWaveDrawingMode() const;

    void enterInRoom(const RoomInfo &room, const QList<ChannelMetadata> &channels, const QString &password = "");

    LoginService *getLoginService() const;

    const QSharedPointer<controller::AudioController>& getAudioController() const;

    virtual controller::NinjamController *getNinjamController() const;

    Service *getNinjamService();

    static QStringList getBotNames();

    AudioPeak getRoomStreamPeak();

    bool isStarted() const;

    login::Location getGeoLocation(const QString &ip);

    virtual QSharedPointer<audio::LocalInputNode> createInputNode(int groupIndex);

    virtual float getSampleRate() const = 0;

    float getEncodingQuality() const;

    static QByteArray newGUID();

    const Settings &getSettings() const;

    // store settings
    void storeMetronomeSettings(float metronomeGain, float metronomePan, bool metronomeMuted);
    void storeIntervalProgressShape(int shape);

    void storeWindowSettings(bool maximized, const QPointF &location, const QSize &size);
    void storeIOSettings(int firstIn, int lastIn, int firstOut, int lastOut,
                         QString audioInputDevice, QString audioOutputDevice,
                         const QList<bool> &midiInputStatus, const QList<bool> &syncOutputsStatus);

    void storeIOSettings(int firstIn, int lastIn, int firstOut, int lastOut,
                         QString audioInputDevice, QString audioOutputDevice);

    void storeMultiTrackRecordingStatus(bool savingMultiTracks);
    bool isMultiTrackRecordingActivated() const;
    void storeMultiTrackRecordingPath(const QString &newPath);
    void storeDirNameDateFormat(const QString &newDateFormat);

    void storeJamRecorderStatus(const QString &writerId, bool status);

    bool isJamRecorderActivated(const QString &writerId) const;

    void storePrivateServerSettings(const QString &server, quint16 serverPort, const QString &password);

    void storeChannelInstrumentIndex(int channelId, int instrumentIndex);

    bool isUsingCustomMetronomeSounds() const;

    void setTranslationLanguage(const QString &languageCode);
    inline QString getTranslationLanguage() const
    {
        return settings.getTranslation();
    }

    void setBuiltInMetronome(const QString &metronomeAlias);
    void setCustomMetronome(const QString &primaryBeatFile, const QString &offBeatFile,
                            const QString &accentBeatFile);

    QString getMetronomeFirstBeatFile() const;
    QString getMetronomeOffBeatFile() const;
    QString getMetronomeAccentBeatFile() const;

    void saveEncodedAudio(const QString &userName, quint8 channelIndex,
                          const QSharedPointer<QByteArray>& encodedAudio);

    AbstractMp3Streamer *getRoomStreamer() const;

    void setUserName(const QString &newUserName);

    QString getUserName() const;

    bool userNameWasChoosed() const;

    bool setTheme(const QString &themeName);

    // TODO: move this code to NinjamController.
    void finishUploads();     // used to send the last part of ninjam intervals when audio is stopped.

    virtual QString getUserEnvironmentString() const;

    // to remembering ninjamers controls (pan, level, gain, boost)
    QSharedPointer<UsersDataCache> getUsersDataCache();     // TODO hide this from callers. Create a function in mainController to update the CacheEntries, so MainController is used as a Fa√ßade.

    bool userIsBlockedInChat(const QString &userName) const;

    void storeMeteringSettings(bool showingMaxPeaks, persistence::MeterMode meterOption);

    static QString getSuggestedUserName();

    QMap<QString, QString> getJamRecoders() const;

    void setChannelReceiveStatus(const QString &userFullName, quint8 channelIndex,
                                 bool receiveChannel);

    // looper settings
    void storeLooperPreferredLayerCount(quint8 layersCount);
    void storeLooperPreferredMode(persistence::LooperMode looperMode);
    void storeLooperAudioEncodingFlag(bool encodeAudioWhenSaving);
    void storeLooperFolder(const QString &newLooperFolder);
    bool getLooperAudioEncodingFlag() const;
    quint8 getLooperBitDepth() const;

    // collapse settings
    void setLocalChannelsCollapsed(bool collapsed);
    void setBottomSectionCollapsed(bool collapsed);
    void setChatSectionCollapsed(bool collapsed);
    bool isLocalChannelsCollapsed() const;
    bool isBottomSectionCollapsed() const;
    bool isChatSectionCollapsed() const;

    static bool crashedInLastExecution();
    static QString getVersionFromLogContent();

    EmojiManager *getEmojiManager() const;

    qint8 getChatFontSizeOffset() const;

    void setPublicChatActivated(bool activated);

    bool isVoiceChatActivated(int channelID) const;
    void setVoiceChatActivated(int channelID, bool activated);

    const static QSize MAX_VIDEO_SIZE;

signals:
    void themeChanged();
    void userBlockedInChat(const QString &userName);
    void userUnblockedInChat(const QString &userName);
    void ipResolved(const QString &ip);

public slots:
    // sync methods
    virtual void startMidiClock() const = 0;
    virtual void stopMidiClock() const = 0;
    virtual void continueMidiClock() const = 0;
    virtual void sendMidiClockPulse() const = 0;

    virtual void setSampleRate(int newSampleRate);
    void setEncodingQuality(float newEncodingQuality);
    void storeLooperBitDepth(quint8 bitDepth);

    void storeRemoteUserRememberSettings(bool boost, bool level, bool pan, bool mute, bool lowCut);
    void storeCollapsibleSectionsRememberSettings(bool localChannels, bool bottomSection,
                                                  bool chatSection);

    void blockUserInChat(const QString &userNameToBlock);
    void unblockUserInChat(const QString &userNameToUnblock);

    void processCapturedFrame(int frameID, const QImage &frame);

    virtual void connectInNinjamServer(const ninjam::client::ServerInfo &server);

    void storeChatFontSizeOffset(qint8 fontSizeOffset);

protected:

    static QString LOG_CONFIG_FILE;

    QSharedPointer<controller::AudioController> audioController;

    LoginService loginService;

    QMap<QString, login::Location> locationCache;
    QSet<int> channelChatActivated;
    QMap<int, int> channelInstrumentIndex;

    // ninjam
    QScopedPointer<Service, QScopedPointerDeleteLater> ninjamService;
    QScopedPointer<controller::NinjamController, QScopedPointerDeleteLater> ninjamController;

    Settings settings;

    virtual controller::NinjamController *createNinjamController() = 0;

    MainWindow *mainWindow;

    // map the input channel indexes to a GUID (used to upload audio to ninjam server)
    QMap<quint8, UploadIntervalData> audioIntervalsToUpload;
    QScopedPointer<UploadIntervalData> videoIntervalToUpload;

    mutable QMutex mutex;

    virtual void setupNinjamControllerSignals();
    virtual void clearNinjamControllerSignals();

    virtual void setCSS(const QString &css) = 0;

    virtual QVector<midi::MidiMessage> pullMidiMessagesFromDevices() = 0;     // pull midi messages generated by midi controllers. This function is called just one time in each audio processing cicle.

    virtual void syncWithNinjamIntervalStart(uint intervalLenght);

    FFMpegMuxer videoEncoder;

private:
    QSharedPointer<AbstractMp3Streamer> roomStreamer;
    QString currentStreamingRoomID;

    bool started;

    void tryConnectInNinjamServer(const RoomInfo &ninjamRoom, const QList<ChannelMetadata> &channels,
                                  const QString &password = "");

    QList<JamRecorder *> jamRecorders;

    QList<JamRecorder *> getActiveRecorders() const;

    QSharedPointer<UsersDataCache> usersDataCache;

    const static quint8 CAMERA_FPS;

    bool canGrabNewFrameFromCamera() const;

    quint64 lastFrameTimeStamp;

    void updateMetronomeSound();

    uint getFramesPerInterval() const;

    static const QString CRASH_FLAG_STRING;

    EmojiManager emojiManager;

    QSet<QString> chatBlockedUsers;

protected slots:

    // ninjam
    virtual void disconnectFromNinjamServer(const ninjam::client::ServerInfo &server);
    virtual void quitFromNinjamServer(const QString &error);

    void enqueueAudioDataToUpload(const controller::AudioChannelData& channelData, const QByteArray& encodedData);
    void enqueueVideoDataToUpload(const QByteArray &encodedData, bool isFirstPart);

    virtual void updateBpi(int newBpi);
    virtual void updateBpm(int newBpm);

    // TODO move this slot to NinjamController
    virtual void handleNewNinjamInterval();

    void requestCameraFrame(int intervalPosition);

};

inline MainWindow *MainController::getMainWindow() const
{
    return mainWindow;
}

inline void MainController::setLocalChannelsCollapsed(bool collapsed)
{
    settings.collapseSettings.setLocalChannelsCollapsed(collapsed);
}

inline void MainController::setBottomSectionCollapsed(bool collapsed)
{
    settings.collapseSettings.setBottomSectionCollapsed(collapsed);
}

inline void MainController::setChatSectionCollapsed(bool collapsed)
{
    settings.collapseSettings.setChatSectionCollapsed(collapsed);
}

inline bool MainController::isLocalChannelsCollapsed() const
{
    return settings.collapseSettings.isLocalChannelsCollapsed();
}

inline bool MainController::isBottomSectionCollapsed() const
{
    return settings.collapseSettings.isBottomSectionCollapsed();
}

inline bool MainController::isChatSectionCollapsed() const
{
    return settings.collapseSettings.isChatSectionCollapsed();
}

inline qint8 MainController::getChatFontSizeOffset() const
{
    return settings.getChatFontSizeOffset();
}

inline EmojiManager *MainController::getEmojiManager() const
{
    return const_cast<EmojiManager *>(&emojiManager);
}

inline QSharedPointer<UsersDataCache> MainController::getUsersDataCache()
{
    return usersDataCache;
}

inline bool MainController::userNameWasChoosed() const
{
    return !settings.getUserName().isEmpty();
}

inline AbstractMp3Streamer *MainController::getRoomStreamer() const
{
    return roomStreamer.data();
}

inline QString MainController::getMetronomeFirstBeatFile() const
{
    return settings.metronomeSettings.getCustomPrimaryBeatFile();
}

inline QString MainController::getMetronomeOffBeatFile() const
{
    return settings.metronomeSettings.getCustomOffBeatFile();
}

inline QString MainController::getMetronomeAccentBeatFile() const
{
    return settings.metronomeSettings.getCustomAccentBeatFile();
}

inline bool MainController::isUsingCustomMetronomeSounds() const
{
    return settings.metronomeSettings.isUsingCustomSounds();
}

inline bool MainController::isJamRecorderActivated(const QString &writerId) const
{
    return settings.recordingSettings.isJamRecorderActivated(writerId);
}

inline bool MainController::isMultiTrackRecordingActivated() const
{
    return settings.recordingSettings.isSaveMultiTrackActivated();
}

inline const Settings &MainController::getSettings() const
{
    return settings;
}

inline float MainController::getEncodingQuality() const
{
    return settings.audioSettings.getEncodingQuality();
}

inline bool MainController::isStarted() const
{
    return started;
}

inline const QSharedPointer<controller::AudioController>& MainController::getAudioController() const
{
    return audioController;
}

inline controller::NinjamController *MainController::getNinjamController() const
{
    return ninjamController.data();
}

inline Service *MainController::getNinjamService()
{
    return ninjamService.data();
}

inline QString MainController::getCurrentStreamingRoomID() const
{
    return currentStreamingRoomID;
}

inline int MainController::getLastTracksLayout() const
{
    return settings.getLastTracksLayoutOrientation();
}

inline void MainController::storeTracksLayoutOrientation(quint8 layout)
{
    settings.storeTracksLayoutOrientation(layout);
}

inline void MainController::storeTracksSize(bool usingNarrowedTracks)
{
    settings.storeTracksSize(usingNarrowedTracks);
}

inline bool MainController::isUsingNarrowedTracks() const
{
    return settings.isUsingNarrowedTracks();
}

inline void MainController::storeWaveDrawingMode(persistence::WaveDrawingMode drawingMode)
{
    settings.meteringSettings.setWaveDrawingMode(drawingMode);
}

inline persistence::WaveDrawingMode MainController::getLastWaveDrawingMode() const
{
    return settings.meteringSettings.getWaveDrawingMode();
}

inline void MainController::setMainWindow(MainWindow *mainWindow)
{
    this->mainWindow = mainWindow;
}

inline void MainController::storeLooperBitDepth(quint8 bitDepth)
{
    settings.looperSettings.setWaveFilesBitDepth(bitDepth);
}

inline quint8 MainController::getLooperBitDepth() const
{
    return settings.looperSettings.getWaveFilesBitDepth();
}

inline void MainController::storeLooperPreferredLayerCount(quint8 layersCount)
{
    settings.looperSettings.setPreferredLayersCount(layersCount);
}

inline void MainController::storeLooperPreferredMode(persistence::LooperMode looperMode)
{
    settings.looperSettings.setPreferredMode(looperMode);
}

inline void MainController::storeLooperAudioEncodingFlag(bool encodeAudioWhenSaving)
{
    settings.looperSettings.setEncodingAudioWhenSaving(encodeAudioWhenSaving);
}

inline void MainController::storeLooperFolder(const QString &newLooperFolder)
{
    settings.looperSettings.setLoopsFolder(newLooperFolder);
}

inline bool MainController::getLooperAudioEncodingFlag() const
{
    return settings.looperSettings.isEncodingAudioWhenSaving();
}

inline void MainController::storeRemoteUserRememberSettings(bool boost, bool level, bool pan,
                                                            bool mute, bool lowCut)
{
    settings.rememberSettings.setRememberingBoost(boost);
    settings.rememberSettings.setRememberingLevel(level);
    settings.rememberSettings.setRememberingPan(pan);
    settings.rememberSettings.setRememberingMute(mute);
    settings.rememberSettings.setRememberingLowCut(lowCut);
}

inline void MainController::storeCollapsibleSectionsRememberSettings(bool localChannels,
                                                                     bool bottomSection,
                                                                     bool chatSection)
{
    settings.rememberSettings.setRememberLocalChannels(localChannels);
    settings.rememberSettings.setRememberBottomSection(bottomSection);
    settings.rememberSettings.setRememberChatSection(chatSection);
}
} // namespace

#endif
